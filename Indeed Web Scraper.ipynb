{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "96908e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary Libraries\n",
    "from typing import Optional, Dict, Tuple\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from time import sleep\n",
    "from rich import print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a5620584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add settings and Configurations\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "#chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7970179c",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome(service=ChromeService(ChromeDriverManager().install()), options = chrome_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e48d5d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "website = 'https://ng.indeed.com/'\n",
    "browser.get(website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "657bda6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6645f80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_search = browser.find_element(By.ID, 'text-input-what')\n",
    "search_button = browser.find_element(By.CLASS_NAME, 'yosegi-InlineWhatWhere-primaryButton')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6a38e24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_search.clear()\n",
    "input_search.send_keys('Dentist Jobs')\n",
    "browser.execute_script(\"arguments[0].click();\", search_button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "685b70a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the HTML source code of the page after it has fully loaded\n",
    "html = browser.page_source\n",
    "\n",
    "# Parse the HTML using BeautifulSoup\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "2e5e3d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(job_listing):\n",
    "    # Extract job title\n",
    "    title = job_listing.find(\"a\").find(\"span\").text.strip()\n",
    "    \n",
    "    # Extract company name if available, otherwise assign an empty string\n",
    "    try:\n",
    "        company = job_listing.find('span', class_='css-92r8pb eu4oa1w0').text.strip()\n",
    "    except AttributeError:\n",
    "        company = ''\n",
    "    \n",
    "    # Extract job location if available, otherwise assign an empty string\n",
    "    try:\n",
    "        location  = job_listing.find('div', class_='css-1p0sjhy eu4oa1w0').text.strip()\n",
    "    except AttributeError:\n",
    "        location = ''\n",
    "        \n",
    "    # Extract salary information if available, otherwise assign an empty string\n",
    "    try:\n",
    "        salary  = job_listing.find('div', class_='metadata salary-snippet-container css-5zy3wz eu4oa1w0').text.strip()\n",
    "    except AttributeError:\n",
    "        salary = ''\n",
    "    \n",
    "    # Extract job type if available, otherwise assign an empty string\n",
    "    try:\n",
    "        job_type = job_listing.find('div', class_='metadata css-5zy3wz eu4oa1w0').text.strip()\n",
    "    except AttributeError:\n",
    "        job_type = ''\n",
    "    \n",
    "    # Extract date posted\n",
    "    date_posted = job_listing.find('span', class_='css-qvloho eu4oa1w0').text.strip()\n",
    "    \n",
    "    # Extract job summary\n",
    "    summary = job_listing.find('div', class_='css-9446fg eu4oa1w0').text.strip()\n",
    "    \n",
    "    # Return a tuple containing all the extracted information\n",
    "    return (title, company, location, salary, job_type, date_posted, summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "871bed6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_listings = [get_data(i)for i in soup.find_all('div', class_='job_seen_beacon')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e00f8a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Data saved to job_data.csv\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Data saved to job_data.csv\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert list of records into a DataFrame\n",
    "df = pd.DataFrame(job_listings, columns=['Title', 'Company', 'Location', 'Salary', 'Job Type', 'Date Posted', 'Summary'])\n",
    "\n",
    "# Save DataFrame to a CSV file\n",
    "df.to_csv('indeed_job_data.csv', index=False)\n",
    "\n",
    "print(\"Data saved to job_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web-scraping",
   "language": "python",
   "name": "web-scraping"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
